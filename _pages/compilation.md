---
layout: archive
title: "Compilation of Papers on Cultural Alignment and AI"
permalink: /compilation/
author_profile: true
---

{% include base_path %}


## Introduction
Welcome to this repository, a comprehensive collection of research and papers focused on cultural alignment and human value alignment in Artificial Intelligence, with a special emphasis on Language Models. This field is crucial for ensuring AI systems are developed and implemented in ways that are sensitive to diverse cultural norms and values.

### Purpose
The purpose of this repository is to:
- Provide a centralized resource for researchers, students, and AI enthusiasts.
- Foster understanding of AI's alignment with various human values and cultural contexts.
- Encourage discussion and further research in this vital AI development area.

## Contents
- [Papers](#papers)
- [Conferences and Workshops](#conferences-and-workshops)
- [How to Contribute](#how-to-contribute)

## Papers
A compilation of academic papers, articles, and publications exploring AI, Language Models, and cultural value alignment.

### 2023
- [Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models](https://arxiv.org/pdf/2304.03738.pdf)
- [Cultural Alignment in Large Language Models: An Explanatory Analysis Based on Hofstede's Cultural Dimensions](https://arxiv.org/abs/2309.12342)
- [Whose Opinions Do Language Models Reflect?](https://arxiv.org/pdf/2303.17548.pdf)
- [The Myth of Culturally Agnostic AI Models](https://arxiv.org/ftp/arxiv/papers/2211/2211.15271.pdf)
- [In Conversation with Artificial Intelligence: Aligning Language Models with Human Values](https://link.springer.com/article/10.1007/s13347-023-00606-x)
- [Probing Pre-Trained Language Models for Cross-Cultural Differences in Values](https://arxiv.org/abs/2203.13722)

### 2022
- [Cultural Incongruencies in Artificial Intelligence](https://arxiv.org/pdf/2211.13069.pdf)
- [The Myth of Culturally Agnostic AI Models](https://arxiv.org/ftp/arxiv/papers/2211/2211.15271.pdf)

### 2021
- [Gender bias, social bias, and representation in Bollywood and Hollywood](https://www.sciencedirect.com/science/article/pii/S266638992100283X)

### 2020
- [Artificial Intelligence, Values, and Alignment](https://link.springer.com/article/10.1007/s11023-020-09539-2)


## Conferences and Workshops
Information on relevant conferences, seminars, and workshops with sessions dedicated to cultural alignment in AI.

- [Cultures in AI/AI in Culture - A NeurIPS 2022 Workshop](https://ai-cultures.github.io/) - December, NeurIPS 2022.
- [Socially Responsible Language Modelling Research](https://solar-neurips.github.io/)) - December, NeurIPS 2023.
- [Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP)](https://aclanthology.org/volumes/2023.c3nlp-1/) - May, Association for Computational Linguistics 2023


## How to Contribute
Contributions are welcome! Hereâ€™s how you can help:
- **Add New Resources**: Found something not listed? Add it!
- **Update Existing Entries**: Keep information current, correct inaccuracies.
- **Improve Organization**: Suggestions for a more user-friendly repository are welcome.

To contribute:
1. [Fork the repository](https://github.com/reemim/reemim.github.io/edit/master/_pages/compilation.md).
2. Make your changes.
3. Submit a pull request with a clear description of your modifications.

### Contact
For questions and suggestions, feel free to [contact us](mailto:reem.masoud.22@ucl.ac.uk).


